# 03.1 • Componentes Disponíveis na Instalação do Cluster ODP/Ambari

A tabela abaixo descreve detalhadamente cada serviço/componente disponibilizado na tela de seleção do cluster ODP/Ambari. Para cada item, está apresentada sua finalidade e em quais situações ou cenários pode ser utilizado.

| Serviço               | Versão | Descrição breve                                                                        | Situação de uso principal                                                                                                         |
|-----------------------|--------|----------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------|
| **HDFS**              | 3.3.6  | Sistema de arquivos distribuído base do ecossistema Hadoop                             | Armazenamento distribuído, alta disponibilidade e tolerância a falhas para dados de big data.                                     |
| **YARN + MapReduce2** | 3.3.6  | Gerenciador de recursos e processamento distribuído (NextGen MapReduce do Hadoop)      | Execução de workloads de processamento Hadoop batch, agendamento de tarefas, base para execução de aplicações distribuídas.       |
| **Tez**               | 0.10.2 | Framework de processamento de consultas em DAG (topo de YARN), otimizado para Hive     | Melhora o desempenho de queries Hive e Pig; recomendado para cargas analíticas intensivas.                                        |
| **Hive**              | 3.1.3  | Data warehouse para análise ad hoc via SQL e gerenciamento de grandes volumes de dados | Consultas SQL sobre dados armazenados em HDFS, integração BI, ETL, análises exploratórias.                                        |
| **HBase**             | 2.5.6  | Banco de dados NoSQL distribuído e escalável sobre HDFS                                | Armazenamento de dados semi-estruturados, aplicações OLTP, persistência de logs, integrações em tempo real.                       |
| **Sqoop**             | 1.4.7  | Ferramenta de transferência bulk entre Hadoop e bancos relacionais                     | Migração de dados, integração com bancos SQL para ingestão/extração de grandes volumes.                                           |
| **Oozie**             | 5.2.1  | Orquestrador de workflows Hadoop (inclui web console)                                  | Criação, agendamento e controle de pipelines complexos de processamento na plataforma.                                            |
| **ZooKeeper**         | 3.8.3  | Serviço centralizado e confiável para coordenação distribuída                          | Sincronização de serviços distribuídos (HBase, Kafka, Hadoop), gerenciamento de líderes, locks e configuração dinâmica.           |
| **Infra Solr**        | 0.2.0  | Serviço core utilizado por componentes Ambari                                          | Suporte a funcionalidades internas (ex: indexação para LogSearch e outros serviços de infra).                                     |
| **Ambari Metrics**    | 0.1.0  | Sistema de coleta, armazenamento e visualização de métricas do cluster                 | Acompanhamento do desempenho, monitoramento de saúde e análise histórica do ambiente.                                             |
| **Atlas**             | 2.3.0  | Plataforma de catalogação, governança e linhagem de metadados                          | Governança, compliance, data discovery, rastreamento de origem e uso dos dados no Data Lake.                                      |
| **Kafka**             | 2.8.1  | Plataforma distribuída para streaming de mensagens                                     | Ingestão massiva de eventos e logs, pipelines de dados em tempo real, integração com Hadoop/Spark.                                |
| **Knox**              | 2.0.0  | Gateway unificado de autenticação e acesso a APIs Hadoop                               | Centralização da segurança e acesso externo restrito aos serviços do cluster.                                                     |
| **Log Search**        | 0.5.0  | Agregador, analisador e visualizador de logs do cluster (Technical Preview)            | Monitoramento centralizado de logs, troubleshooting operacional e auditoria.                                                      |
| **Ranger**            | 2.4.0  | Plataforma de segurança e controle de acesso para Hadoop                               | Gerenciamento centralizado de políticas de acesso e auditoria para dados e serviços do cluster.                                   |
| **Ranger KMS**        | 2.4.0  | Servidor de gerenciamento de chaves criptográficas (integra Ranger)                    | Criptografia de dados em repouso (HDFS), proteção de chaves sensíveis do cluster.                                                 |
| **NiFi**              | 1.24.0 | Sistema visual, robusto e confiável de integração e fluxo de dados                     | Ingestão, transformação e roteamento de fluxos de dados entre múltiplas fontes e destinos, integração IoT/streaming.              |
| **NiFi Registry**     | 0.8.0  | Central de armazenamento e controle de versões de artefatos NiFi                       | Gerenciamento colaborativo de templates, fluxos e recursos compartilhados em ambientes complexos NiFi/MiNiFi.                     |
| **Spark2**            | 2.4.8  | Engine de processamento em larga escala (versão 2.x)                                   | Workloads batch e streaming, aplicações legadas que requerem compatibilidade com Spark 2.                                         |
| **Spark3**            | 3.4.2  | Engine moderno para processamento distribuído em memória (versão 3.x)                  | Big Data analytics, machine learning, integração com SQL, bibliotecas modernas em PySpark/Scala; recomendado para novos projetos. |
| **Zeppelin Notebook** | 0.10.1 | Notebook web interativo para análise de dados e visualização                           | Exploração interativa de dados, análises colaborativas, prototipagem de código Spark, SQL, Scala, Python e outros.                |
| **Flink**             | 1.17.0 | Plataforma open source para processamento distribuído de fluxos e lotes                | Pipeline de dados de baixa latência/alta performance, streaming em tempo real e ETL avançada.                                     |
| **Hue**               | 4.11.0 | Interface web unificada para interação com o cluster Hadoop                            | Consultas SQL, gerenciamento de arquivos HDFS/Hive, interface amigável para usuários finais e analistas de dados.                 |

Notas:
- Fonte de versões: docs/XX - Docs PIBIC/ODP-VDF.xml (ODP-1.2.2.0-128). Componentes Ambari/Utils (Infra Solr, Ambari Metrics, Log Search, Hue) não constam no VDF e têm versões conforme repositórios Ambari/Utils disponibilizados.

---

## Componentes efetivamente utilizados no cluster 

A tabela abaixo lista os serviços que foram efetivamente provisionados no ambiente cdp.dev.br, conforme o arquivo `docs/XX - Docs PIBIC/blueprint.json`.

| Serviço               | Versão | Componentes-chave observados no blueprint                                                                                 |
|-----------------------|--------|---------------------------------------------------------------------------------------------------------------------------|
| **HDFS**              | 3.3.6  | NAMENODE, SECONDARY_NAMENODE, DATANODE, NFS_GATEWAY, HDFS_CLIENT                                                          |
| **YARN + MapReduce2** | 3.3.6  | RESOURCEMANAGER, NODEMANAGER, HISTORYSERVER, TIMELINE_READER, APP_TIMELINE_SERVER, YARN_REGISTRY_DNS, MAPREDUCE2_CLIENT |
| **ZooKeeper**         | 3.8.3  | ZOOKEEPER_SERVER, ZOOKEEPER_CLIENT                                                                                        |
| **Hive**              | 3.1.3  | HIVE_SERVER, HIVE_METASTORE, HIVE_CLIENT, MYSQL_SERVER (metastore)                                                        |
| **Tez**               | 0.10.2 | TEZ_CLIENT                                                                                                                |
| **HBase**             | 2.5.6  | HBASE_MASTER, HBASE_REGIONSERVER, HBASE_CLIENT, PHOENIX_QUERY_SERVER                                                      |
| **Kafka**             | 2.8.1  | KAFKA_BROKER                                                                                                              |
| **Ranger**            | 2.4.0  | RANGER_ADMIN, RANGER_USERSYNC, RANGER_TAGSYNC                                                                             |
| **Infra Solr**        | 0.2.0  | INFRA_SOLR, INFRA_SOLR_CLIENT                                                                                             |
| **NiFi**              | 1.24.0 | NIFI_MASTER, NIFI_CA                                                                                                      |
| **Spark3**            | 3.4.2  | SPARK3_JOBHISTORYSERVER, LIVY2_SERVER, SPARK3_LIVY2_SERVER, SPARK3_THRIFTSERVER, SPARK3_CLIENT                           |

> **Como usar este documento:**
> Use a primeira tabela como referência de compatibilidade da stack (VDF) e a segunda para conferir o que foi realmente instalado no seu cluster a partir do blueprint.


---

## Ordem recomendada de instalação dos serviços

Premissas:
- A instalação é procedural: adicionar e configurar 1 serviço por vez, validando a saúde no Ambari antes de seguir para o próximo.
- Exceção: HDFS, ZooKeeper e YARN + MapReduce2 podem ser selecionados e instalados juntos no setup inicial do wizard (documento "03-configuracao-servicos.md"). Essa base foi a adotada no blueprint do ambiente cdp.dev.br.
- Esta ordem considera dependências técnicas, práticas comuns em produção e o que foi efetivamente usado no blueprint.

Fluxo recomendado
1) Setup inicial (wizard): instalar juntos
- ZooKeeper
- HDFS
- YARN + MapReduce2
- Tez

2) Pós-setup (instalar um por vez nesta sequência)
1. Hive (Metastore + HiveServer2 + Cliente)
   - Pré-requisitos: HDFS, YARN, Tez e banco para o metastore (MySQL/PostgreSQL). No blueprint, foi utilizado MySQL local.
2. Ambari Infra Solr
   - Motivo: base para auditoria/logs e integração com serviços de segurança (ex.: Ranger). Facilita troubleshooting futuro.
3. Ranger (Admin + Usersync + Tagsync)
   - Pré-requisitos: Banco (Postgres no Ambari Server por padrão) e, idealmente, Infra Solr para auditoria. Após subir, crie políticas para HDFS/Hive/Kafka/HBase conforme necessidade.
4. Kafka
   - Pré-requisitos: ZooKeeper. Útil para pipelines streaming; pode ser integrado ao Ranger.
5. HBase (Master, RegionServer, Cliente) + Phoenix Query Server
   - Pré-requisitos: HDFS e ZooKeeper. Pode receber políticas do Ranger.
6. NiFi (NIFI_CA, NIFI_MASTER)
   - Pré-requisitos: opcionalmente Kafka e HDFS, dependendo dos fluxos. Integra-se ao Ranger via plugin.
7. Spark3 (JobHistoryServer, Livy2, ThriftServer, Client)
   - Pré-requisitos: HDFS, YARN e, para uso do ThriftServer, é recomendado ter Hive disponível.

3) Opcionais e tardios (conforme necessidade)
- Atlas, Knox, Oozie, Sqoop, Spark2, NiFi Registry, Zeppelin, Flink, Hue, Ambari Metrics, Log Search.

Resumo de dependências (mapa lógico)
- ZooKeeper → requerido por HBase, Kafka e por features de coordenação em serviços distribuídos.
- HDFS → base para YARN (históricos), Hive, HBase, Spark3 e Tez.
- YARN → base de execução para Tez e Spark3.
- Tez → recomendado para Hive (melhora performance das queries).
- Metastore (MySQL/Postgres) → requerido por Hive.
- Ambari Infra Solr → recomendado antes de Ranger (auditoria; também útil para Log Search/Atlas).
- Ranger → políticas de segurança para HDFS, Hive, Kafka, HBase e demais serviços suportados.
- Kafka → geralmente antecede NiFi quando fluxos dependerem de tópicos Kafka.
- Hive → recomendado antes do Spark ThriftServer quando os usuários usarão SQL sobre Spark com catálogos compatíveis.

Boas práticas de validação entre etapas
- Após instalar cada serviço, execute os Service Checks no Ambari e verifique a saúde (Ambari → Actions → Run Service Check). Corrija alertas antes de prosseguir.
- Garanta portas e firewall liberados conforme "00-prérequisitos.md".
- Se SELinux estiver enforcing, revise políticas; recomendamos permissive durante a instalação inicial (ver 00-prérequisitos.md).
- Na documentação quanto à boas práticas, existe mensão quanto à problemas de acesso que podem ocorrer em caso de o SELinux ser ativado. Caso por algum razão você perca o 
acesso ao terminal das suas máquinas, potencialmente o problema pode ser o SELinux, neste sentido, existe um procedimento documentado que pode ser executado para livrar este problema. Analise-o posteriormente.
